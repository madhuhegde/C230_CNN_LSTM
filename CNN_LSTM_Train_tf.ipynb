{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow\n",
    "import matplotlib\n",
    "import json, pickle\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "import pdb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from LossHistory import LossHistory\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "from CNN_LSTM_load_data import  generator_train, generator_test\n",
    "from CNN_LSTM_split_data import generate_feature_train_list, generate_feature_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "config = json.load(open('config/config.json'))\n",
    "base_dir = config['base_dir']\n",
    "model_save_dir = config[\"model_save_dir\"]\n",
    "history_dir = config[\"history_dir\"]\n",
    "base_image_dir = base_dir+\"images/\"\n",
    "base_label_dir = base_dir+\"labels/\"\n",
    "test_image_dir = base_image_dir + \"test/\"\n",
    "test_label_dir = base_label_dir + \"test/\"\n",
    "train_image_dir = base_image_dir + \"train/\"\n",
    "train_label_dir = base_label_dir + \"train/\"\n",
    "\n",
    "\n",
    "# 7 phases for surgical operation\n",
    "class_labels = {\"Preparation\":0, \"CalotTriangleDissection\":1, \"ClippingCutting\":2, \n",
    "           \"GallbladderDissection\":3, \"GallbladderPackaging\":4, \"CleaningCoagulation\":5, \"GallbladderRetraction\":6}\n",
    "\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "# Dimensions of input feature \n",
    "frames = 25    #Number of frames over which LSTM prediction happens\n",
    "channels = 3  #RGB\n",
    "rows = 224    \n",
    "columns = 224 \n",
    "\n",
    "#training parameters\n",
    "BATCH_SIZE = 8 # Need GPU with 32 GB RAM for BATCH_SIZE > 16\n",
    "nb_epochs = 14 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback function if detailed log required\n",
    "class History(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.train_acc.append(logs.get('categorical_accuracy'))\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):    \n",
    "        self.val_acc.append(logs.get('val_categorical_accuracy'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        \n",
    "# Implement ModelCheckPoint callback function to save CNN model\n",
    "class CNN_ModelCheckpoint(tensorflow.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model, filename):\n",
    "        self.filename = filename\n",
    "        self.cnn_model = model\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.max_val_acc = 0\n",
    "        \n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):    \n",
    "        val_acc = logs.get('val_categorical_accuracy')\n",
    "        if(val_acc > self.max_val_acc):\n",
    "           self.max_val_acc = val_acc\n",
    "           self.cnn_model.save(self.filename)     \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 13,569,280\n",
      "Non-trainable params: 1,145,408\n",
      "_________________________________________________________________\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Use pretrained VGG16 \n",
    "video = Input(shape=(frames,rows,columns,channels))\n",
    "cnn_base = VGG16(input_shape=(rows,columns,channels),\n",
    "                 weights=\"imagenet\",\n",
    "                 #weights = None, \n",
    "                 include_top=False)\n",
    "                             \n",
    "\n",
    "cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "\n",
    "cnn_model = Model(inputs=cnn_base.input, outputs=cnn_out)\n",
    "\n",
    "#cnn.trainable = True\n",
    "\n",
    "#Use Transfer learning and train only last 4 layers                 \n",
    "for layer in cnn_model.layers[:-11]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "for layer in cnn_model.layers:\n",
    "   print(layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 2, 224, 224, 3)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 512)            14714688  \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 17,080,135\n",
      "Trainable params: 15,934,727\n",
      "Non-trainable params: 1,145,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build LSTM network\n",
    "encoded_frames = TimeDistributed(cnn_model)(video)\n",
    "encoded_sequence = LSTM(512, name='lstm1')(encoded_frames)\n",
    "\n",
    "# RELU or tanh?\n",
    "hidden_layer = Dense(units=512, activation=\"relu\")(encoded_sequence)\n",
    "#hidden_layer = Dense(units=512, activation=\"tanh\")(encoded_sequence)\n",
    "\n",
    "dropout_layer = Dropout(rate=0.5)(hidden_layer)\n",
    "outputs = Dense(units=num_classes, activation=\"softmax\")(dropout_layer)\n",
    "lstm_model = Model(video, outputs)\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to Adam\n",
    "optimizer = Nadam(lr=0.00001,\n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999,\n",
    "                  epsilon=1e-08,\n",
    "                  schedule_decay=0.004)\n",
    "\n",
    "#softmax crossentropy\n",
    "lstm_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520 2328\n"
     ]
    }
   ],
   "source": [
    "train_samples  = generate_feature_train_list(train_image_dir, train_label_dir)\n",
    "validation_samples = generate_feature_test_list(test_image_dir, test_label_dir)\n",
    "train_len = int(len(train_samples)/(BATCH_SIZE*frames))\n",
    "train_len = (train_len)*BATCH_SIZE*frames\n",
    "train_samples = train_samples[0:train_len]\n",
    "validation_len = int(len(validation_samples)/(BATCH_SIZE*frames))\n",
    "validation_len = (validation_len-2)*BATCH_SIZE*frames\n",
    "validation_samples = validation_samples[0:validation_len]\n",
    "print (train_len, validation_len)\n",
    "\n",
    "saveCNN_Model = CNN_ModelCheckpoint(cnn_model, model_save_dir+\"cnn_model1.h5\")\n",
    "\n",
    "#define callback functions\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=2),\n",
    "             ModelCheckpoint(filepath=model_save_dir+'best_model1.h5', monitor='val_loss',\n",
    "             save_best_only=True),\n",
    "             saveCNN_Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/madhuhegde/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\t 0\n",
      "\t 4\n",
      "\t 8\n",
      "\t 12\n",
      "\t 16\n",
      "\t 20\n",
      "\t 24\n",
      "\t 28\n",
      "\t 32\n",
      "\t 36\n",
      "\t 40\n",
      "Epoch 1/2\n",
      "\t 44\n",
      " 1/16 [>.............................] - ETA: 1:44 - loss: 2.1204 - categorical_accuracy: 0.0000e+00\t 48\n",
      " 2/16 [==>...........................] - ETA: 1:15 - loss: 2.0830 - categorical_accuracy: 0.0000e+00\t 52\n",
      " 3/16 [====>.........................] - ETA: 1:02 - loss: 2.0457 - categorical_accuracy: 0.0000e+00\t 56\n",
      " 4/16 [======>.......................] - ETA: 54s - loss: 2.0181 - categorical_accuracy: 0.0625     \t 60\n",
      " 5/16 [========>.....................] - ETA: 48s - loss: 1.9913 - categorical_accuracy: 0.0500\t 0\n",
      " 6/16 [==========>...................] - ETA: 42s - loss: 1.9689 - categorical_accuracy: 0.0833\t 4\n",
      " 7/16 [============>.................] - ETA: 37s - loss: 1.9581 - categorical_accuracy: 0.1429\t 8\n",
      " 8/16 [==============>...............] - ETA: 32s - loss: 1.9490 - categorical_accuracy: 0.1562\t 12\n",
      " 9/16 [===============>..............] - ETA: 28s - loss: 1.9360 - categorical_accuracy: 0.1667\t 16\n",
      "10/16 [=================>............] - ETA: 24s - loss: 1.9173 - categorical_accuracy: 0.2250\t 20\n",
      "11/16 [===================>..........] - ETA: 19s - loss: 1.8976 - categorical_accuracy: 0.2727\t 24\n",
      "12/16 [=====================>........] - ETA: 15s - loss: 1.8736 - categorical_accuracy: 0.3333\t 28\n",
      "13/16 [=======================>......] - ETA: 11s - loss: 1.8415 - categorical_accuracy: 0.3846\t 32\n",
      "14/16 [=========================>....] - ETA: 7s - loss: 1.8224 - categorical_accuracy: 0.4286 \t 36\n",
      "15/16 [===========================>..] - ETA: 3s - loss: 1.7922 - categorical_accuracy: 0.4667\t 40\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.2740 - categorical_accuracy: 1.0000\n",
      "16/16 [==============================] - 73s 5s/step - loss: 1.7586 - categorical_accuracy: 0.5000 - val_loss: 1.2740 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "\t 44\n",
      " 1/16 [>.............................] - ETA: 54s - loss: 1.3958 - categorical_accuracy: 0.7500\t 48\n",
      " 2/16 [==>...........................] - ETA: 51s - loss: 1.3109 - categorical_accuracy: 0.8750\t 52\n",
      " 3/16 [====>.........................] - ETA: 47s - loss: 1.2422 - categorical_accuracy: 0.9167\t 56\n",
      " 4/16 [======>.......................] - ETA: 44s - loss: 1.2200 - categorical_accuracy: 0.9375\t 60\n",
      " 5/16 [========>.....................] - ETA: 40s - loss: 1.1724 - categorical_accuracy: 0.9500\t 0\n",
      " 6/16 [==========>...................] - ETA: 36s - loss: 1.0982 - categorical_accuracy: 0.9583\t 4\n",
      " 7/16 [============>.................] - ETA: 33s - loss: 1.0587 - categorical_accuracy: 0.9643\t 8\n",
      " 8/16 [==============>...............] - ETA: 29s - loss: 1.0185 - categorical_accuracy: 0.9688\t 12\n",
      " 9/16 [===============>..............] - ETA: 25s - loss: 0.9501 - categorical_accuracy: 0.9722\t 16\n",
      "10/16 [=================>............] - ETA: 22s - loss: 0.8892 - categorical_accuracy: 0.9750\t 20\n",
      "11/16 [===================>..........] - ETA: 18s - loss: 0.8422 - categorical_accuracy: 0.9773\t 24\n",
      "12/16 [=====================>........] - ETA: 14s - loss: 0.8021 - categorical_accuracy: 0.9792\t 28\n",
      "13/16 [=======================>......] - ETA: 11s - loss: 0.7578 - categorical_accuracy: 0.9808\t 32\n",
      "14/16 [=========================>....] - ETA: 7s - loss: 0.7254 - categorical_accuracy: 0.9821 \t 36\n",
      "15/16 [===========================>..] - ETA: 3s - loss: 0.6845 - categorical_accuracy: 0.9833\t 40\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.1229 - categorical_accuracy: 1.0000\n",
      "16/16 [==============================] - 68s 4s/step - loss: 0.6507 - categorical_accuracy: 0.9844 - val_loss: 0.1229 - val_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "train_generator = generator_train(train_samples, batch_size=BATCH_SIZE, frames_per_clip=frames,shuffle=True)\n",
    "validation_generator = generator_test(validation_samples, batch_size=BATCH_SIZE, frames_per_clip=frames, shuffle=False)\n",
    "\n",
    "history = lstm_model.fit_generator(train_generator, \n",
    "            steps_per_epoch=int(len(train_samples)/(BATCH_SIZE*frames)), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=int(len(validation_samples)/(BATCH_SIZE*frames)), \n",
    "            #callbacks = [history],\n",
    "            callbacks = callbacks,\n",
    "            epochs=nb_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
